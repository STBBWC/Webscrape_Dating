{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Adding a New Dating Profile\n",
    "Using Classification or Clustering for a New Dating Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.0.0)\r\n",
      "Requirement already satisfied: ipykernel in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (6.16.0)\r\n",
      "Requirement already satisfied: jupyter-console in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (6.4.4)\r\n",
      "Requirement already satisfied: notebook in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (6.4.12)\r\n",
      "Requirement already satisfied: qtconsole in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (5.3.2)\r\n",
      "Requirement already satisfied: nbconvert in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (7.2.1)\r\n",
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter) (8.0.2)\r\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (5.4.0)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (7.4.1)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (7.34.0)\r\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (5.9.2)\r\n",
      "Requirement already satisfied: tornado>=6.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (6.2)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (0.1.6)\r\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (21.3)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (24.0.1)\r\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (0.1.3)\r\n",
      "Requirement already satisfied: debugpy>=1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (1.6.3)\r\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel->jupyter) (1.5.6)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipywidgets->jupyter) (4.0.3)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipywidgets->jupyter) (3.0.3)\r\n",
      "Requirement already satisfied: pygments in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter-console->jupyter) (2.13.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter-console->jupyter) (3.0.31)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (0.2.2)\r\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (2.0.4)\r\n",
      "Requirement already satisfied: jinja2>=3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (3.1.2)\r\n",
      "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (0.7.1)\r\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (2.1.1)\r\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (0.7.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (4.11.1)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (1.5.0)\r\n",
      "Requirement already satisfied: tinycss2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (1.1.1)\r\n",
      "Requirement already satisfied: bleach in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (5.0.1)\r\n",
      "Requirement already satisfied: nbformat>=5.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (5.7.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (5.0.0)\r\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbconvert->jupyter) (4.11.1)\r\n",
      "Requirement already satisfied: ipython-genutils in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (0.2.0)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (0.16.0)\r\n",
      "Requirement already satisfied: argon2-cffi in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (21.3.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (1.8.0)\r\n",
      "Requirement already satisfied: prometheus-client in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from notebook->jupyter) (0.14.1)\r\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from qtconsole->jupyter) (2.2.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbconvert->jupyter) (4.4.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbconvert->jupyter) (3.9.0)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (62.3.2)\r\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.18.1)\r\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\r\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\r\n",
      "Requirement already satisfied: entrypoints in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.4)\r\n",
      "Requirement already satisfied: fastjsonschema in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbformat>=5.1->nbconvert->jupyter) (2.16.2)\r\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nbformat>=5.1->nbconvert->jupyter) (4.16.0)\r\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.5)\r\n",
      "Requirement already satisfied: ptyprocess in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.3.2.post1)\r\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from bleach->nbconvert->jupyter) (1.16.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from packaging->ipykernel->jupyter) (3.0.9)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (22.1.0)\r\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (5.10.0)\r\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (1.3.10)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (0.18.1)\r\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.1)\r\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\r\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.3.5)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (1.21.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2018.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (8.0.2)\r\n",
      "Requirement already satisfied: widgetsnbextension in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.0.3)\r\n",
      "Collecting pandas-profiling\r\n",
      "  Downloading pandas_profiling-3.3.0-py2.py3-none-any.whl (268 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m268.0/268.0 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: ipython>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipywidgets) (7.34.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipywidgets) (5.4.0)\r\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipywidgets) (6.16.0)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipywidgets) (3.0.3)\r\n",
      "Requirement already satisfied: matplotlib<3.6,>=3.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (3.5.3)\r\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (6.0)\r\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (1.21.6)\r\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.5,>1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (1.3.5)\r\n",
      "Collecting visions[type_image_path]==0.7.5\r\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m102.7/102.7 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2<3.2,>=2.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (3.1.2)\r\n",
      "Collecting phik<0.13,>=0.11.1\r\n",
      "  Downloading phik-0.12.2-cp37-cp37m-macosx_10_13_x86_64.whl (662 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m662.8/662.8 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting tangled-up-in-unicode==0.2.0\r\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.7/4.7 MB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hRequirement already satisfied: tqdm<4.65,>=4.48.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (4.64.1)\r\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (2.28.1)\r\n",
      "Collecting missingno<0.6,>=0.4.2\r\n",
      "  Downloading missingno-0.5.1-py3-none-any.whl (8.7 kB)\r\n",
      "Collecting pydantic<1.10,>=1.8.1\r\n",
      "  Downloading pydantic-1.9.2-cp37-cp37m-macosx_10_9_x86_64.whl (2.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting seaborn<0.12,>=0.10.1\r\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m292.8/292.8 kB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: scipy<1.10,>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas-profiling) (1.7.3)\r\n",
      "Collecting statsmodels<0.14,>=0.13.2\r\n",
      "  Downloading statsmodels-0.13.2-cp37-cp37m-macosx_10_9_x86_64.whl (9.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.5/9.5 MB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting multimethod<1.9,>=1.4\r\n",
      "  Downloading multimethod-1.8-py3-none-any.whl (9.8 kB)\r\n",
      "Collecting htmlmin==0.1.12\r\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting joblib~=1.1.0\r\n",
      "  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m309.8/309.8 kB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: attrs>=19.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (22.1.0)\r\n",
      "Collecting networkx>=2.4\r\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (9.2.0)\r\n",
      "Collecting imagehash\r\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m296.5/296.5 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: debugpy>=1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.1)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\r\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\r\n",
      "Requirement already satisfied: tornado>=6.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.2)\r\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\r\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.31)\r\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: pygments in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.13.0)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (62.3.2)\r\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jinja2<3.2,>=2.11.1->pandas-profiling) (2.1.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (4.37.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (0.11.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas!=1.4.0,<1.5,>1.1->pandas-profiling) (2018.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pydantic<1.10,>=1.8.1->pandas-profiling) (4.4.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (1.26.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (3.4)\r\n",
      "Collecting patsy>=0.5.2\r\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m233.8/233.8 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: entrypoints in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\r\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.11.1)\r\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->pandas-profiling) (1.16.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\r\n",
      "Collecting PyWavelets\r\n",
      "  Downloading PyWavelets-1.3.0-cp37-cp37m-macosx_10_13_x86_64.whl (4.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.3/4.3 MB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hBuilding wheels for collected packages: htmlmin\r\n",
      "  Building wheel for htmlmin (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27082 sha256=55a34b1318fcc5fba6aaa88ffa8bc1540bc48c2e90ec22860884c3e5269381ba\r\n",
      "  Stored in directory: /Users/wadewilson/Library/Caches/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\r\n",
      "Successfully built htmlmin\r\n",
      "Installing collected packages: htmlmin, tangled-up-in-unicode, PyWavelets, pydantic, patsy, networkx, multimethod, joblib, imagehash, visions, statsmodels, seaborn, phik, missingno, pandas-profiling\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.2.0\r\n",
      "    Uninstalling joblib-1.2.0:\r\n",
      "      Successfully uninstalled joblib-1.2.0\r\n",
      "  Attempting uninstall: seaborn\r\n",
      "    Found existing installation: seaborn 0.12.0\r\n",
      "    Uninstalling seaborn-0.12.0:\r\n",
      "      Successfully uninstalled seaborn-0.12.0\r\n",
      "Successfully installed PyWavelets-1.3.0 htmlmin-0.1.12 imagehash-4.3.1 joblib-1.1.1 missingno-0.5.1 multimethod-1.8 networkx-2.6.3 pandas-profiling-3.3.0 patsy-0.5.3 phik-0.12.2 pydantic-1.9.2 seaborn-0.11.2 statsmodels-0.13.2 tangled-up-in-unicode-0.2.0 visions-0.7.5\r\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.21.6)\r\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (3.5.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (1.21.6)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (21.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (4.37.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib) (9.2.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.4.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.11.2)\r\n",
      "Requirement already satisfied: pandas>=0.23 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (1.3.5)\r\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (3.5.3)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (1.7.3)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (1.21.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.4.4)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.37.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2018.4)\r\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.4.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\r\n",
      "\u001B[31mERROR: Invalid requirement: '_pickle'\u001B[0m\u001B[31m\r\n",
      "\u001B[0mRequirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sklearn) (1.0.2)\r\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.6)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.1.1)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.64.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jupyter\n",
    "!pip3 install pandas\n",
    "!pip3 install ipywidgets widgetsnbextension pandas-profiling\n",
    "!pip3 install numpy\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install _pickle\n",
    "!pip3 install sklearn\n",
    "!pip3 install tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import _pickle as pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook as tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading the Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                    Bios  \\\n0        Typical twitter fanatic. Infuriatingly humble thinker. Lifelong coffee practitioner. Organizer.   \n1  Web junkie. Analyst. Infuriatingly humble introvert. Food nerd. Lifelong music fanatic. Coffee lover.   \n2     Avid web maven. Food practitioner. Gamer. Twitter fanatic. Pop culture scholar. Zombie evangelist.   \n3                      Twitteraholic. Extreme web fanatic. Food buff. Infuriatingly humble entrepreneur.   \n4        Bacon enthusiast. Falls down a lot. Freelance social media fan. Infuriatingly humble introvert.   \n\n   Movies  TV  Religion  Music  Sports  Books  Politics  \n0       5   3         4      1       3      6         7  \n1       7   9         5      1       9      4         0  \n2       1   2         6      5       6      5         4  \n3       5   2         7      8       2      6         6  \n4       6   6         6      4       3      6         3  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bios</th>\n      <th>Movies</th>\n      <th>TV</th>\n      <th>Religion</th>\n      <th>Music</th>\n      <th>Sports</th>\n      <th>Books</th>\n      <th>Politics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Typical twitter fanatic. Infuriatingly humble thinker. Lifelong coffee practitioner. Organizer.</td>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Web junkie. Analyst. Infuriatingly humble introvert. Food nerd. Lifelong music fanatic. Coffee lover.</td>\n      <td>7</td>\n      <td>9</td>\n      <td>5</td>\n      <td>1</td>\n      <td>9</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Avid web maven. Food practitioner. Gamer. Twitter fanatic. Pop culture scholar. Zombie evangelist.</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Twitteraholic. Extreme web fanatic. Food buff. Infuriatingly humble entrepreneur.</td>\n      <td>5</td>\n      <td>2</td>\n      <td>7</td>\n      <td>8</td>\n      <td>2</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bacon enthusiast. Falls down a lot. Freelance social media fan. Infuriatingly humble introvert.</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the cleaned DF\n",
    "with open(\"profiles.pkl\",'rb') as fp:\n",
    "    raw_df = pickle.load(fp)\n",
    "\n",
    "# Viewing the DF    \n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading the Clustered Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                Bios  \\\n6595              Typical pop culture nerd. Infuriatingly humble internet maven. Alcohol evangelist.   \n6596      Avid web junkie. Lifelong alcohol guru. Hardcore reader. Award-winning twitter evangelist.   \n6597           Music ninja. Bacon fanatic. Reader. Total communicator. Unapologetic beer specialist.   \n6598                     Communicator. Bacon lover. Award-winning introvert. Amateur internet ninja.   \n6599  Unapologetic tv aficionado. Devoted twitter enthusiast. Typical coffee guru. Falls down a lot.   \n\n      Movies   TV  Religion  Music  Sports  Books  Politics  Cluster #  \n6595     7.0  9.0       0.0    0.0     2.0    2.0       4.0          9  \n6596     4.0  3.0       6.0    3.0     7.0    7.0       2.0          2  \n6597     1.0  4.0       0.0    4.0     9.0    2.0       5.0          0  \n6598     6.0  2.0       0.0    3.0     8.0    9.0       1.0          9  \n6599     2.0  1.0       8.0    7.0     0.0    5.0       5.0         10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bios</th>\n      <th>Movies</th>\n      <th>TV</th>\n      <th>Religion</th>\n      <th>Music</th>\n      <th>Sports</th>\n      <th>Books</th>\n      <th>Politics</th>\n      <th>Cluster #</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6595</th>\n      <td>Typical pop culture nerd. Infuriatingly humble internet maven. Alcohol evangelist.</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6596</th>\n      <td>Avid web junkie. Lifelong alcohol guru. Hardcore reader. Award-winning twitter evangelist.</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6597</th>\n      <td>Music ninja. Bacon fanatic. Reader. Total communicator. Unapologetic beer specialist.</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6598</th>\n      <td>Communicator. Bacon lover. Award-winning introvert. Amateur internet ninja.</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6599</th>\n      <td>Unapologetic tv aficionado. Devoted twitter enthusiast. Typical coffee guru. Falls down a lot.</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the clustered DF\n",
    "with open(\"../data/clustered_profiles.pkl\",'rb') as fp:\n",
    "    cluster_df = pickle.load(fp)\n",
    "\n",
    "# Viewing the DF    \n",
    "cluster_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the New Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter new profile information...\n",
      "\n",
      "Example Bio:\n",
      "Bacon enthusiast. Falls down a lot. Freelance social media fan. Infuriatingly humble introvert.\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a new DF row to append later\n",
    "new_profile = pd.DataFrame(columns=raw_df.columns)\n",
    "\n",
    "# Adding random values for new data\n",
    "for i in new_profile.columns[1:]:\n",
    "    new_profile[i] = np.random.randint(0,10,1)\n",
    "\n",
    "# Printing an user interface for inputting new values\n",
    "print(\"Enter new profile information...\\n\\nExample Bio:\\nBacon enthusiast. Falls down a lot. Freelance social media fan. Infuriatingly humble introvert.\")\n",
    "\n",
    "# Asking for new profile data\n",
    "new_profile['Bios'] = input(\"Enter a Bio for yourself: \")\n",
    "\n",
    "# Indexing that new profile data\n",
    "new_profile.index = [raw_df.index[-1] + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Bios  Movies  TV  Religion  Music  Sports  Books  Politics\n6600            5   9         9      4       6      6         7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bios</th>\n      <th>Movies</th>\n      <th>TV</th>\n      <th>Religion</th>\n      <th>Music</th>\n      <th>Sports</th>\n      <th>Books</th>\n      <th>Politics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6600</th>\n      <td></td>\n      <td>5</td>\n      <td>9</td>\n      <td>9</td>\n      <td>4</td>\n      <td>6</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Two Approaches\n",
    "1. Cluster all the profiles again with the new profile\n",
    "\n",
    "2. Classify the new profile with a classification model trained on our previously clustered data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clustering the New Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Appending the new data\n",
    "new_cluster = raw_df.append(new_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating the Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scaling the categories then replacing the old values\n",
    "df = new_cluster[['Bios']].join(pd.DataFrame(scaler.fit_transform(new_cluster.drop('Bios', axis=1)), columns=new_cluster.columns[1:], index=new_cluster.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fitting the vectorizer to the Bios\n",
    "x = vectorizer.fit_transform(df['Bios'])\n",
    "\n",
    "# Creating a new DF that contains the vectorized words\n",
    "df_wrds = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Concating the words DF with the original DF\n",
    "new_df = pd.concat([df, df_wrds], axis=1)\n",
    "\n",
    "# Dropping the Bios because it is no longer needed in place of vectorization\n",
    "new_df.drop('Bios', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9898750354519308"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instantiating PCA\n",
    "pca = PCA()\n",
    "\n",
    "# Fitting and Transforming the DF\n",
    "df_pca = pca.fit_transform(new_df)\n",
    "\n",
    "# Finding the exact number of features that explain at least 99% of the variance in the dataset\n",
    "total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "n_over_99 = len(total_explained_variance[total_explained_variance>=.99])\n",
    "n_to_reach_99 = new_df.shape[1] - n_over_99\n",
    "\n",
    "# Reducing the dataset to the number of features determined before\n",
    "pca = PCA(n_components=n_to_reach_99)\n",
    "\n",
    "# Fitting and transforming the dataset to the stated number of features\n",
    "df_pca = pca.fit_transform(new_df)\n",
    "\n",
    "# Seeing the variance ratio that still remains after the dataset has been reduced\n",
    "pca.explained_variance_ratio_.cumsum()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performing Hierarchical Agglomerative Clustering\n",
    "- First finding the optimum number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'notebook'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/v0/7gtj3bhx74z6w7kx78fhqlmm0000gn/T/ipykernel_26031/3830505945.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;31m# Looping through different iterations for the number of clusters\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotebook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcluster_cnt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;31m# Clustering with different number of clusters\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'notebook'"
     ]
    }
   ],
   "source": [
    "# Setting the amount of clusters to test out\n",
    "cluster_cnt = [i for i in range(2, 20, 1)]\n",
    "\n",
    "# Establishing empty lists to store the scores for the evaluation metrics\n",
    "ch_scores = []\n",
    "\n",
    "s_scores = []\n",
    "\n",
    "db_scores = []\n",
    "\n",
    "# Looping through different iterations for the number of clusters\n",
    "# TODO generating errors, possible tqdm.notebook.tqdm?\n",
    "for i in tqdm(cluster_cnt):\n",
    "    \n",
    "    # Clustering with different number of clusters\n",
    "    hac = AgglomerativeClustering(n_clusters=i)\n",
    "    \n",
    "    hac.fit(df_pca)\n",
    "    \n",
    "    cluster_assignments = hac.labels_\n",
    "    \n",
    "    # Appending the scores to the empty lists\n",
    "    ch_scores.append(calinski_harabasz_score(df_pca, cluster_assignments))\n",
    "    \n",
    "    s_scores.append(silhouette_score(df_pca, cluster_assignments))\n",
    "    \n",
    "    db_scores.append(davies_bouldin_score(df_pca, cluster_assignments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Helper Function to Evaluate the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_eval(y, x):\n",
    "    \"\"\"\n",
    "    Prints the scores of a set evaluation metric. Prints out the max and min values of the evaluation scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a DataFrame for returning the max and min scores for each cluster\n",
    "    df = pd.DataFrame(columns=['Cluster Score'], index=[i for i in range(2, len(y)+2)])\n",
    "    df['Cluster Score'] = y\n",
    "    \n",
    "    print('Max Value:\\nCluster #', df[df['Cluster Score']==df['Cluster Score'].max()])\n",
    "    print('\\nMin Value:\\nCluster #', df[df['Cluster Score']==df['Cluster Score'].min()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluation of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The Calinski-Harabasz Score (find max score):\")\n",
    "cluster_eval(ch_scores, cluster_cnt)\n",
    "\n",
    "print(\"\\nThe Silhouette Coefficient Score (find max score):\")\n",
    "cluster_eval(s_scores, cluster_cnt)\n",
    "\n",
    "print(\"\\nThe Davies-Bouldin Score (find minimum score):\")\n",
    "cluster_eval(db_scores, cluster_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Running HAC\n",
    "Again but with the optimum cluster count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating HAC\n",
    "hac = AgglomerativeClustering(n_clusters=12)\n",
    "\n",
    "# Fitting\n",
    "hac.fit(df_pca)\n",
    "\n",
    "# Getting cluster assignments\n",
    "cluster_assignments = hac.labels_\n",
    "\n",
    "# Unscaling the categories then replacing the scaled values\n",
    "df = df[['Bios']].join(pd.DataFrame(scaler.inverse_transform(df.drop('Bios', axis=1)), columns=df.columns[1:], index=df.index))\n",
    "\n",
    "# Assigning the clusters to each profile\n",
    "df['Cluster #'] = cluster_assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finding the Exact Cluster for our New Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the Cluster # for the new profile\n",
    "profile_cluster = df.loc[new_profile.index]['Cluster #'].values[0]\n",
    "\n",
    "# Using the Cluster # to narrow down the DF\n",
    "profile_df = df[df['Cluster #']==profile_cluster].drop('Cluster #', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vectorizing the Selected Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the vectorizer to the Bios\n",
    "cluster_x = vectorizer.fit_transform(profile_df['Bios'])\n",
    "\n",
    "# Creating a new DF that contains the vectorized words\n",
    "cluster_v = pd.DataFrame(cluster_x.toarray(), index=profile_df.index, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Joining the Vectorized DF to the previous DF\n",
    "profile_df = profile_df.join(cluster_v).drop('Bios', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finding Correlation for Top 10 Similar Profiles to the New Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Trasnposing the DF so that we are correlating with the index(users) and finding the correlation\n",
    "corr = profile_df.T.corr()\n",
    "\n",
    "# Finding the Top 10 similar or correlated users to the new user\n",
    "user_n = new_profile.index[0]\n",
    "\n",
    "# Creating a DF with the Top 10 most similar profiles\n",
    "top_10_sim = corr[[user_n]].sort_values(by=[user_n],axis=0, ascending=False)[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The Top 10 Profiles most likely to Match with the New Profile\n",
    "(Sorted by descending similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_df.loc[top_10_sim.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification of the New Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Importing the Different Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing 3 models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assigning the split variables\n",
    "X = cluster_df.drop([\"Cluster #\"], 1)\n",
    "y = cluster_df['Cluster #']\n",
    "\n",
    "## Vectorizing\n",
    "# Instantiating the Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fitting the vectorizer to the Bios\n",
    "x = vectorizer.fit_transform(X['Bios'])\n",
    "\n",
    "# Creating a new DF that contains the vectorized words\n",
    "df_wrds = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Concating the words DF with the original DF\n",
    "X = pd.concat([X, df_wrds], axis=1)\n",
    "\n",
    "# Dropping the Bios because it is no longer needed in place of vectorization\n",
    "X.drop(['Bios'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling the Data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preparing the New Profile Data\n",
    "For Vectorization purposes, the new profile will have to be able to fit into trained data (has to have the same columns).\n",
    "\n",
    "Two Options:\n",
    "1. __Vectorized the New Profile data with the vectorizer fitted to the dataset as to not include potentially new vocabulary. _(Keeps dimensionality the same)___\n",
    "2. Vectorized the New Profile data with a new vectorizer fitted to it in order to include new vocabulary. _(Increases dimensionality with every new piece of data)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorizing the new data\n",
    "vect_new_prof = vectorizer.transform(new_profile['Bios'])\n",
    "\n",
    "# Quick DF of the vectorized words\n",
    "new_vect_w = pd.DataFrame(vect_new_prof.toarray(), columns=vectorizer.get_feature_names(), index=new_profile.index)\n",
    "\n",
    "# Concatenating the DFs for the new profile data\n",
    "new_vect_prof = pd.concat([new_profile, new_vect_w], 1).drop('Bios', 1)\n",
    "\n",
    "# Scaling the new profile data\n",
    "new_vect_prof = pd.DataFrame(scaler.transform(new_vect_prof), columns=new_vect_prof.columns, index=new_vect_prof.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_vect_prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train, test, splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finding the Best Model\n",
    "- Dummy (Baseline Model)\n",
    "- KNN\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy\n",
    "dummy = DummyClassifier(strategy='stratified')\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "\n",
    "# List of models\n",
    "models = [dummy, knn, svm]\n",
    "\n",
    "# List of model names\n",
    "names = ['Dummy', 'KNN', 'SVM']\n",
    "\n",
    "# Zipping the lists\n",
    "classifiers = dict(zip(names, models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we are dealing with an imbalanced dataset _(because each cluster is not guaranteed to have the same amount of profiles)_, we will resort to using the __Macro Avg__ and __F1 Score__ for evaluating the performances of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary containing the model names and their scores\n",
    "models_f1 = {}\n",
    "\n",
    "# Looping through each model's predictions and getting their classification reports\n",
    "for name, model in classifiers.items():\n",
    "    # Fitting the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('\\n'+ name + ' (Macro Avg - F1 Score):')\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, model.predict(X_test), output_dict=True)\n",
    "    f1 = report['macro avg']['f1-score']\n",
    "    \n",
    "    # Assigning to the Dictionary\n",
    "    models_f1[name] = f1\n",
    "    \n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Model with the Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(max(models_f1, key=models_f1.get), 'Score:', max(models_f1.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using the Best Model to Classify the New Profile\n",
    "_(Optional: Tune the model with GridSearch)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "svm.fit(X, y)\n",
    "\n",
    "# Predicting the New Profile data by determining which Cluster it would belong to\n",
    "designated_cluster = svm.predict(new_vect_prof)\n",
    "\n",
    "designated_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### DF containing the Profiles of the Designated Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "des_cluster = cluster_df[cluster_df['Cluster #']==designated_cluster[0]]\n",
    "\n",
    "des_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finding the Top 10 Similar Profiles to our New Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Appending the new profile data\n",
    "des_cluster = des_cluster.append(new_profile, sort=False)\n",
    "\n",
    "# Fitting the vectorizer to the Bios\n",
    "cluster_x = vectorizer.fit_transform(des_cluster['Bios'])\n",
    "\n",
    "# Creating a new DF that contains the vectorized words\n",
    "cluster_v = pd.DataFrame(cluster_x.toarray(), index=des_cluster.index, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Joining the Vectorized DF to the previous DF and dropping columns\n",
    "des_cluster = des_cluster.join(cluster_v).drop(['Bios', 'Cluster #'], axis=1)\n",
    "\n",
    "des_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Correlations to find similar profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the Top 10 similar or correlated users to the new user\n",
    "user_n = new_profile.index[0]\n",
    "\n",
    "# Trasnposing the DF so that we are correlating with the index(users) and finding the correlation\n",
    "corr = des_cluster.T.corrwith(des_cluster.loc[user_n])\n",
    "\n",
    "# Creating a DF with the Top 10 most similar profiles\n",
    "top_10_sim = corr.sort_values(ascending=False)[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Top 10 Similar profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_df.loc[top_10_sim.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Saving the Classification Model\n",
    "For future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(svm, \"clf_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion on the Two Different Approaches\n",
    "The results for both approaches are the same.  The new profile ends up in the same cluster whether it is clustered or classified to be there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}